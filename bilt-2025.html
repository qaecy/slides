<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>QAECY - BiLT 2025</title>

    <link rel="icon" type="image/x-icon" href="favicon.ico" />

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/qaecy.css" />

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" />

    <style>
      .cue-inline {
        display: inline;
        height: 1rem;
        margin: 0 0 -0.05rem 0 !important;
      }
      .footer-left {
        position: absolute;
        bottom: 27px;
        left: 27px;
        padding: 0;
        margin: 0;
        display: flex;
        flex-direction: row;
        gap: 10px;
        align-content: flex-start;
        justify-content: flex-end;
        align-items: center;
      }
      .footer-left img {
        height: 2.5rem;
        margin: 0;
        padding: 0;
      }
    </style>
  </head>
  <body>
    <div class="reveal">
      <div class="footer-left">
        <img src="dist/img/logos/bilt-10.png" />
        <img src="dist/img/logo.svg" />
      </div>

      <div class="slides">
        <!-- Front -->
        <section>
          <div
            style="
              display: flex;
              flex-direction: row;
              gap: 1rem;
              align-items: center;
              justify-content: center;
            "
          >
            <img src="dist/img/logo.svg" alt="" />
            <span>@</span>
            <img
              style="height: 100px"
              src="dist/img/logos/bilt-10.png"
              alt=""
            />
          </div>
          <p style="font-size: 2.1rem">
            Unlocking AEC Insights with Graph RAG: A Hands-On Lab Session
          </p>
          <img
            src="https://api.qrserver.com/v1/create-qr-code/?data=http://slides.qaecy.com/bilt-2025.html&size=150x150"
            alt="http://slides.qaecy.com/bilt-2025.html"
          />
        </section>

        <!-- Us -->
        <section>
          <section
            data-background-iframe="https://www.qaecy.com/about#hs_cos_wrapper_module_17212009421947"
          >
            <h2 class="bg-transparent-white">Who are we?</h2>
            <img
              class="print-fallback"
              src="dist/img/fallback/AIinAEC2025-about.png"
              alt=""
            />
          </section>
        </section>

        <!-- Agenda -->
        <section>
          <h2>Overall agenda</h2>
          <ul>
            <li class="fragment fade-up">Session 3.1 | 09:30-10:45</li>
            <ul class="fragment fade-up" style="margin-top: 0">
              <li>Why?</li>
              <li>What tech?</li>
              <li>Hands on: Data processing</li>
            </ul>
            <li class="fragment fade-up">Coffee break ‚òï</li>
            <li class="fragment fade-up">Session 3.2 | 11:00-12:15</li>
            <ul class="fragment fade-up" style="margin-top: 0">
              <li>Hands on: RAG</li>
              <li>Perspective and discussion</li>
            </ul>
            <li class="fragment fade-up">Lunch ü•óü•ñüç¥</li>
          </ul>
        </section>

        <!-- Why -->
        <section>
          <section>
            <h2>Why are we here?</h2>
          </section>

          <section data-background-image="dist/img/misc/archive.png">
            <h4 style="color: #fff">The problem:</h4>
            <p style="color: #fff">
              Information is trapped in silos, it's incomplete
              <span style="font-size: 1.5rem"
                >(or in multiple incompatible versions)</span
              >
              and therefore hardly accessible
            </p>
            <aside class="notes">
              We do store data in document management systems and assign
              metadata like revision letters, but often there are duplicates of
              a file and metadata might not be up to date.<br /><br />
              Some files are even scanned copies that are not searchable. And
              even if they are, it typically requires an expert to read through
              the files in order to deduce the requested information.
            </aside>
          </section>

          <section data-background-image="dist/img/misc/trinity-library.png">
            <p style="color: #fff">Library of</p>
            <p style="color: #fff">Trinity College Dublin</p>
            <aside class="notes">
              In a library we add structure to books so we can easily find them,
              but how should they be organised? By author? subject? color? At
              Trinity College Dublin they are organised by size. The limitation
              is that they can only be put in one place, just like the files in
              your file explorer.
            </aside>
          </section>

          <section
            data-background-image="dist/img/misc/tim-berners-lee.png"
            style="height: 100%"
          >
            <div
              style="
                position: absolute;
                right: 0;
                bottom: 0;
                text-align: end;
                background-color: rgba(255, 255, 255, 0.2);
              "
            >
              <p>1991</p>
              <p>World Wide Web</p>
            </div>
            <aside class="notes">
              With the WWW we suddenly had a common language to publish
              documents and create hyperlinks to other documents published by
              other people
            </aside>
          </section>

          <section
            data-background-image="dist/img/misc/yahoo.png"
            style="height: 100%"
          >
            <div
              style="
                position: absolute;
                left: 0;
                bottom: 20vh;
                text-align: start;
                color: #fff;
                width: 200px;
              "
            >
              <p>We need structure. Let's order the web by category!</p>
            </div>
            <aside class="notes">
              As people started publishing content, we needed a way to search
              this information. Yahoo initially tried to do this like a phone
              book. By topic.
            </aside>
          </section>

          <section
            data-background-image="dist/img/misc/google.png"
            style="height: 100%"
          >
            <div
              style="
                position: absolute;
                left: 0;
                text-align: left;
                top: 10vh;
                color: #fff;
                width: 220px;
                background-color: rgba(0, 0, 0, 0.1);
                padding: 0 1rem;
              "
            >
              <p>All we need is a search bar!</p>
            </div>
            <aside class="notes">
              Then came Google who invented a smart page ranking algorithm.<br /><br />
              More incoming links = higher score.<br /><br />
              In the beginnig it was simple keyword search, so if you wanted to
              find the a contry's population you would search for the page that
              would be likely to have this information
              ("Population+europe+2012")
            </aside>
          </section>

          <section
            data-background-image="dist/img/misc/semantic-results.png"
            style="height: 100%"
          >
            <div
              style="position: absolute; right: 0; bottom: 0; text-align: end"
            >
              <p>Semantic<br />results</p>
            </div>
            <aside class="notes">
              Since 2012, Google has been working on displaying semantic
              results. This particular entity recognition feature was probably
              added around 2015.
            </aside>
          </section>

          <section
            data-background-image="dist/img/misc/semantic-search.png"
            style="height: 100%"
          >
            <div
              style="position: absolute; right: 0; bottom: 0; text-align: end"
            >
              <p>Semantic<br />search</p>
              <aside class="notes">
                With semantic search, you can now search more like you would ask
                the question to a person.<br /><br />
                The algorithm understands the intent of your question and finds
                the information in a knowledge graph (more on that later).
              </aside>
            </div>
          </section>

          <section
            data-background-image="dist/img/misc/postit-classify.png"
            style="height: 100%"
          >
            <div
              style="
                position: absolute;
                right: 0;
                bottom: 10vh;
                text-align: end;
                color: #fff;
                width: 40vw;
              "
            >
              <p>The construction industry is still in the Yahoo age</p>
            </div>
            <aside class="notes">
              We think we can solve everything with classification and tidy
              systems. One of the challenges with this strategy is that things
              can typically only belong to one type/class.
            </aside>
          </section>

          <section
            data-background-video="dist/videos/misc/LLM_search_algae.mp4"
            style="height: 100%"
          >
            <div
              style="position: absolute; right: 0; bottom: 0; text-align: end"
            >
              <p>Large Language Models<br />are changing the way we search</p>
            </div>
            <aside class="notes">
              Perplexity is a serious competitor to Google and with ChatGPT and
              Gemini we are getting used to basically have a conversation with
              the AI.<br /><br />
              I will not go much into details on the technology behind, but it's
              all about probability and math.
            </aside>
          </section>
        </section>

        <!-- RAG Intro -->
        <section>
          <section>
            <h4>But what if I wish to search my own documents?</h4>
          </section>

          <section>
            <video
              data-autoplay
              data-preload
              src="dist/videos/misc/PDF_chat2.mp4"
            ></video>
            <aside class="notes">
              There are free services that allow you to chat with a PDF and
              these are great for a quick Q&A with your document
            </aside>
          </section>

          <section>
            <h4>RAG</h4>
            <p>Retrieval-Augmented Generation</p>
            <aside class="notes">They would typically use a RAG approach</aside>
          </section>

          <section
            data-background-image="dist/img/rag/rag_simple.svg"
            data-background-size="40%"
          >
            <aside class="notes">
              Very simply speaking, the app will extract the text from your PDF
              and add it to the prompt along with your question and some
              instructions on what to do with the information in the text.
            </aside>
          </section>

          <section>
            <h4>And what if I wish to search across multiple documents?</h4>
          </section>

          <section>
            <div>
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <div>
                  <img
                    src="dist/img/rag/f_embedding.svg"
                    alt=""
                    style="height: 200px"
                  />
                </div>
                <div>
                  <h3 style="color: black">
                    \( \rightarrow [-0.2, 0.1, \dots, -0.5, 0.1] \)
                  </h3>
                </div>
              </div>
            </div>
            <aside class="notes">
              If you wish to search across multiple documents the text body
              becomes too big for the query.<br /><br />
              In this case, there is a pre step in converting all the text
              fragments into so-called vector embeddings.
            </aside>
          </section>

          <section>
            <div
              style="
                display: flex;
                justify-content: center;
                align-items: center;
              "
            >
              <div>
                <p style="font-size: 26px">
                  \[ \begin{bmatrix} 0.125 & -2.103 & \dots & -2.005 & 0.012 \\
                  0.615 & -1.142 & \dots & 1.945 & -2.113 \\ \vdots & \vdots &
                  \ddots & \vdots & \vdots \\ 0.712 & 1.153 & \dots & -1.721 &
                  -0.852 \\ -0.925 & -0.903 & \dots & 1.044 & -1.412
                  \end{bmatrix} \rightarrow \]
                </p>
              </div>
              <div>
                <img src="dist/img/rag/db.svg" style="height: 200px" />
              </div>
            </div>
            <aside class="notes">
              The vector embeddings are put in a special type of database called
              a vector database, and based on your search term, these databases
              will give you the text fragments that are most related.<br /><br />
              It's al based on mathematical similarities between the vectors and
              it is kind of mind blowing how well it actually works.
            </aside>
          </section>

          <section
            data-background-image="dist/img/rag/rag_simple2.svg"
            data-background-size="40%"
          >
            <aside class="notes">
              Only the relevant text fragments from the vector database are then
              added to the prompt.
            </aside>
          </section>

          <section data-background-image="dist/img/misc/copilot.jpg">
            <aside class="notes">
              With the technologies available this is also getting quite common
              now, and you will find generic non-industry specific solutions
              that support it.<br /><br />
              For example Microsoft Co-pilot that works with Microsoft 365
            </aside>
          </section>

          <section>
            <h4>
              And if I want to also include results from my CAD files, BIM
              models and tasks in my FM-system?
            </h4>
            <h4>And what about information that constantly changes?</h4>
          </section>

          <section
            data-background-image="dist/img/misc/take-it-easy.jpeg"
            data-background-size="40%"
          >
            <aside class="notes">
              This is were it gets harder and where you can no longer depend on
              the generic tools
            </aside>
          </section>
        </section>

        <!-- Graph RAG -->
        <section>
          <section>
            <h2>Graph RAG</h2>
          </section>

          <section>
            <p>
              At <img src="dist/img/logo.svg" class="inline-logo" /> we process
              documents through a set of pipelines to establish the RAG
              foundation
            </p>
            <p class="fragment">
              In addition to vector embeddings we produce a
              <span style="text-decoration: underline">Knowledge Graph</span>
            </p>
          </section>

          <section>
            <p>First we need to understand what a Knowledge Graph is</p>
            <img
              src="https://api.qrserver.com/v1/create-qr-code/?data=https://lbd-hackers.github.io/slides/20221116_BILT.html&size=100x100"
              alt="https://lbd-hackers.github.io/slides/20221116_BILT.html"
            /><br />
            <a href="https://lbd-hackers.github.io/slides/20221116_BILT.html"
              >BiLT 2022 presentation</a
            >
            <aside class="notes">
              My former colleague Alex and I gave a deeper presentation on this
              at BiLT 2022 in Valencia. You can take a look at it later but here
              we will just briefly introduce the concept.
            </aside>
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/undirected-graph.html"
          >
            <p class="bg-transparent-white">
              A graph is a network of nodes and edges
            </p>
            <img
              src="dist/img/fallback/KG1.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/directed-graph.html"
          >
            <p class="bg-transparent-white">
              In a knowledge graph, the edges are directed
            </p>
            <img
              src="dist/img/fallback/KG2.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/spo1.html"
          >
            <p class="bg-transparent-white">
              One node-edge-node relationship is called a "triple" and describes
              a "statement" or a "fact"
            </p>
            <img
              src="dist/img/fallback/KG3.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/spo2.html"
          >
            <p class="bg-transparent-white">
              A triple consists of a Subject, a predicate and an Object
            </p>
            <img
              src="dist/img/fallback/KG4.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/spo3.html"
          >
            <p class="bg-transparent-white">An example from a BIM model</p>
            <img
              src="dist/img/fallback/KG5.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/spo4.html"
          >
            <p class="bg-transparent-white">
              As more facts are added, the object in one triple becomes the
              subject in another
            </p>
            <img
              src="dist/img/fallback/KG6.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/spo5.html"
          >
            <p class="bg-transparent-white">
              Objects can also represent simple data properties
            </p>
            <img
              src="dist/img/fallback/KG7.png"
              alt=""
              class="print-fallback"
            />
            <aside class="notes">
              BIM models are essentially graphs, and one of the things we do at
              QAECY is to tear them apart and take out all the relevant
              context.<br /><br />
              What spaces are at what storeys, what windows are adjacent to
              which rooms, what chairs are located in which space etc.
            </aside>
          </section>

          <section>
            <p>
              These graphs can grow to unbelievable sizes.<br />
              <img
                src="dist/img/logos/DBpedia.svg"
                class="inline-logo"
                style="height: 60px; transform: translateY(5.5px)"
              />
              consists of 9.5 billion triples!
            </p>
          </section>

          <section
            data-background-iframe="https://dbpedia.org/page/The_Hague_University_of_Applied_Sciences"
          >
            <div class="bg-transparent-white">
              <a
                href="https://dbpedia.org/page/The_Hague_University_of_Applied_Sciences"
                >The Hague University of Applied Sciences at DBpedia</a
              >
            </div>
            <img
              src="dist/img/fallback/BiLT2025-DBPedia.png"
              alt=""
              class="print-fallback"
            />
            <aside class="notes">
              This is the DBPedia entry for this building. You will see that it
              describes facts such as a reference to an image, where it is
              located, geocoordinates, an abstract, when it was established etc.
            </aside>
          </section>

          <!-- Mads Mikkelsen -->
          <section
            style="pointer-events: none"
            data-background-iframe="dist/html/cytoscape/mads-mikkelsen.html"
          >
            <img
              class="print-fallback"
              src="dist/img/misc/mads-mikkelsen-query.png"
              alt=""
            />
            <aside class="notes">
              You can query the graph, and when you do that you essentially
              describe a pattern in the graph that should be matched<br /><br />
              Things that are prefixed with ? are variables (ex ?theActor,
              ?movie)<br /><br />
              Things that are not are constants (ex Mads Mikkelsen, starring)
            </aside>
          </section>

          <section data-background-iframe="https://bit.ly/48kp6l0">
            <div class="bg-transparent-white">
              <a
                style="pointer-events: all"
                href="https://bit.ly/48kp6l0"
                target="_blank"
                >https://dbpedia.org/sparql</a
              >
            </div>
            <p class="print-fallback" style="font-size: 2rem">
              https://bit.ly/48kp6l0
            </p>
            <img
              class="print-fallback"
              src="dist/img/misc/mads-mikkelsen-query2.png"
              alt=""
            />
            <aside class="notes">
              In SPARQL language, the query looks like this and here I will
              execute it on the actual DBPedia live.<br /><br />
              You see how fast it is even with 9,5 billion triples?<br /><br />
              Therefore: Capture as much information about your real estate
              assets as possible. Size is not a limitation!<br /><br />
              You hopefully also see how versatile this data structure is. I
              don't imagine anyone considering this query when originally
              building the data structure - this is vastly different from the
              world of relational databases!
            </aside>
          </section>

          <section>
            <pre><code data-trim class="text hljs" data-line-numbers="1-6|7-16|7-75|77-81"><script type="text/template">
Your job is to convert NLP questions to SPARQL queries. You are conservative, so if there is no obvious answer to the question, you will simply reply with "undefined". If there is a match you  return the SPARQL query and nothing else.

Used prefixes:
PREFIX qcy:   <https://dev.qaecy.com/ont#>
PREFIX qcy-e: <https://dev.qaecy.com/enum#>
PREFIX text:  <http://jena.apache.org/text#>

The kind of queries you understand are:

# List windows
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Space ;
    	qcy:value ?label .
}

# List doors
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Door ;
    	qcy:value ?label .
}

# List spaces on second floor
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
      qcy:entityCategory qcy-e:Space ;
      qcy:value ?label .
  	?storey a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Storey ;
    	qcy:containsSpace ?match .
    (?storey ?score) text:query (qcy:value "Level 2~") .
  FILTER(?score > 3)
}

# Show slabs on second floor
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
      qcy:entityCategory qcy-e:Slab ;
      qcy:value ?label .
  	?storey a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Storey ;
    	qcy:hasElement ?match .
    (?storey ?score) text:query (qcy:value "Level 2~") .
  FILTER(?score > 3)
}

# Show windows adjacent to space A101
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
      qcy:entityCategory qcy-e:Door ;
      qcy:value ?label .
  	?space a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Space ;
    	qcy:adjacentElement ?match .
    (?space ?score) text:query (qcy:value "A101~") .
  FILTER(?score > 3)
}

# Show elements inside space A102
SELECT ?match ?label
WHERE {
    ?match a qcy:BIMEntity ;
      qcy:value ?label .
  	?space a qcy:BIMEntity ;
  		qcy:entityCategory qcy-e:Space ;
    	qcy:containsElement ?match .
    (?space ?score) text:query (qcy:value "A102~") .
  FILTER(?score > 3)
}

Below this line you find the question you should map to a query
---------------------


Show windows on second floor
</script></code></pre>
            <aside class="notes">
              If we use a RAG approach to converting Natural Language to SPARQL
              queries it could look like this. 1. provide instructions and
              examples and 2. insert the user request.
            </aside>
          </section>

          <section
            data-background-video="dist/videos/misc/NL-SPARQL.mp4"
            data-background-size="contain"
          >
            <aside class="notes">
              This is a demonstration of how we use this technology. Since we
              process individual IFCs and establish the graph as a glue between
              them we can even perform a query across multiple models.
            </aside>
          </section>

          <section
            data-background-video="dist/videos/portal/Search_Combined_Models.mp4"
            data-background-size="contain"
          ></section>
        </section>

        <!-- Lab session 1 -->
        <section>
          <section>
            <h2>Data Processing</h2>
          </section>

          <section>
            <p>
              So now we know that we need graphs and Vector embeddings, but how
              do we build these?
            </p>
          </section>

          <section>
            <p>TODO: quick introduction to what we will be creating here...</p>
          </section>

          <section>
            <img
              src="https://api.qrserver.com/v1/create-qr-code/?data=https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/01_data_integration.ipynb&size=250x250"
              alt="https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/01_data_integration.ipynb"
            /><br />
            <a
              href="https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/01_data_integration.ipynb"
              >Notebook 1</a
            >
          </section>
        </section>

        <!-- Break -->
        <section>
          <h2>Coffee break ‚òï</h2>
        </section>

        <!-- RAG and LLMs -->
        <section>
          <section>
            <h2>RAG and LLMs</h2>
            <p>Retrieval Augmented Generation & <br />Large Language Models</p>
          </section>

          <section>
            <h3>LLMs</h3>
            <ul>
              <li>
                Base LLMs (like GPT-4) are very big Neural Networks, consisting
                of billions of parameters, that have been trained on vast
                amounts of data.
              </li>
              <li>
                However they <b>haven't been trained on</b> and
                <b>don't have direct access</b> to private (unseen) data.
              </li>
            </ul>
          </section>

          <section>
            <h3>3 Ways to Expose LLMs to Unseen Data</h3>
            <ol>
              <li>Training a new LLM</li>
              <li>Fine-Tuning an existing LLM</li>
              <li>Performing Retrieval Augmented Generation (RAG)</li>
            </ol>
          </section>

          <section>
            <h3>LLM Training & Fine-Tuning Challenges</h3>
            <ul>
              <li>Costs</li>
              <li>Complexity</li>
              <li>Updating problem</li>
              <li>Poor/No information access control</li>
            </ul>
          </section>

          <section>
            <h3>Retrieval Augmented Generation</h3>
            <p>
              In simple terms, <b>RAG</b> describes a setup through which an LLM
              is provided with direct access to information relevant to the
              user's question, which is not part of the training data.
            </p>
          </section>

          <section>
            <h3>RAG Benefits</h3>
            <ul>
              <li>
                Splits <b>information retrieval</b> from <b>text generation</b>
              </li>
              <li>Very cheap and fast to update</li>
              <li>Allows more explicit control on information access</li>
              <li>Scales efficiently</li>
            </ul>
          </section>

          <section>
            <h3>Training & RAG</h3>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <div style="text-align: center">
                <p style="margin-bottom: 5px">Training / Fine-Tuning</p>
                <img
                  src="dist/img/rag/llm_ft.svg"
                  alt=""
                  style="height: 150px"
                />
              </div>
            </div>
            <div style="text-align: center">
              <p style="margin-bottom: 5px">RAG</p>
              <img
                src="dist/img/rag/llm_rag.svg"
                alt=""
                style="height: 220px"
              />
            </div>
          </section>
        </section>

        <!-- Base RAG -->
        <section>
          <section>
            <h2>Base RAG</h2>
          </section>

          <section>
            <h3>Base RAG Architecture</h3>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <div>
                <div style="text-align: center">
                  <img
                    src="dist/img/rag/rag.svg"
                    alt=""
                    style="height: 520px"
                  />
                </div>
              </div>
            </div>
          </section>

          <section>
            <h3>Processing</h3>
            <h6 style="color: black">Text-Heavy Documents</h6>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <div style="text-align: center">
                <img
                  src="dist/img/rag/doc_transform.svg"
                  alt=""
                  style="height: 300px"
                />
              </div>
            </div>
          </section>

          <section>
            <h3>Processing</h3>
            <h6 style="color: black">Multimodal Documents</h6>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <div style="text-align: center">
                <img
                  src="dist/img/rag/docx_transform.svg"
                  alt=""
                  style="height: 300px"
                />
              </div>
            </div>
          </section>

          <section>
            <h3>Processing</h3>
            <h6 style="color: black">Basic Principle</h6>
            <div>
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <div>
                  <img
                    src="dist/img/rag/f_split.svg"
                    alt=""
                    style="height: 280px"
                  />
                </div>
                <div>
                  <h3 style="color: black">\( \rightarrow \)</h3>
                </div>
                <div>
                  <img
                    src="dist/img/rag/docx_f.svg"
                    alt=""
                    style="height: 200px"
                  />
                </div>
              </div>
            </div>
            <div class="fragment">
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <h3 style="color: black; margin-right: 20px">\( f : \)</h3>
                <p
                  style="
                    color: black;
                    font-size: 30px;
                    text-align: left;
                    font-style: italic;
                  "
                >
                  simple chunking function ...or a deep neural network
                </p>
              </div>
            </div>
          </section>

          <section>
            <h3>Embeddings</h3>
            <div>
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <div>
                  <img
                    src="dist/img/rag/f_embedding.svg"
                    alt=""
                    style="height: 200px"
                  />
                </div>
                <div>
                  <h3 style="color: black">
                    \( \rightarrow [-0.2, 0.1, \dots, -0.5, 0.1] \)
                  </h3>
                </div>
              </div>
            </div>
            <div class="fragment">
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <h3 style="color: black; margin-right: 20px">\( f : \)</h3>
                <p
                  style="
                    color: black;
                    font-size: 30px;
                    text-align: left;
                    font-style: italic;
                  "
                >
                  deep neural network trained to produce vector representations
                  of the input data
                </p>
              </div>
            </div>
          </section>

          <section>
            <h3>Vector Database</h3>
            <div
              style="
                display: flex;
                justify-content: center;
                align-items: center;
              "
            >
              <div>
                <p style="font-size: 26px">
                  \[ \begin{bmatrix} 0.125 & -2.103 & \dots & -2.005 & 0.012 \\
                  0.615 & -1.142 & \dots & 1.945 & -2.113 \\ \vdots & \vdots &
                  \ddots & \vdots & \vdots \\ 0.712 & 1.153 & \dots & -1.721 &
                  -0.852 \\ -0.925 & -0.903 & \dots & 1.044 & -1.412
                  \end{bmatrix} \rightarrow \]
                </p>
              </div>
              <div>
                <img src="dist/img/rag/db.svg" style="height: 200px" />
              </div>
            </div>
            <div class="fragment">
              <div
                style="
                  display: flex;
                  justify-content: center;
                  align-items: center;
                "
              >
                <p style="text-align: left">
                  Storing vectors along with metadata and content
                </p>
              </div>
            </div>
          </section>

          <section>
            <h3>Searching</h3>
            <p style="text-align: center">
              Embedding a query and calculating its distance (eg <b>cosine</b>)
              to the other data points.
            </p>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <img
                src="dist/img/rag/vectors_distance.svg"
                style="height: 350px"
              />
            </div>
            <p style="text-align: center">
              <b>K Nearest Neighbors</b> (KNN) as the search result
            </p>
          </section>

          <section>
            <h3>Indexing</h3>
            <p style="text-align: center">
              Speeding up retrieval by pre-calculating communities.
            </p>
            <div
              style="
                display: flex;
                justify-content: space-around;
                align-items: center;
              "
            >
              <img
                src="dist/img/rag/vectors_clusters.svg"
                style="height: 350px"
              />
            </div>
            <p style="text-align: center">
              <b>Approximate Nearest Neighbor</b> (ANN)
            </p>
          </section>

          <section>
            <h3>Response</h3>
            <p style="text-align: left; font-size: 1.6rem">
              The LLM is now provided with the search results as additional
              <b>context</b> to produce a response to the user's question.
            </p>
            <div style="stroke: gray; stroke-width: 4px; text-align: left">
              <div>
                <h6 style="font-size: 25px; color: black; margin-bottom: 0px">
                  Instructions
                </h6>
                <p
                  style="font-size: 20px; font-style: italic; margin-left: 45px"
                >
                  "Given the context provided answer the question as an
                  assistant that..."
                </p>
              </div>
              <div>
                <h4 style="font-size: 25px; color: black; margin-bottom: 0px">
                  Question
                </h4>
                <p
                  style="font-size: 20px; font-style: italic; margin-left: 45px"
                >
                  "What is the main entrance's corridor width?"
                </p>
              </div>
              <div>
                <h4 style="font-size: 25px; color: black; margin-bottom: 0px">
                  Context
                </h4>
                <ul
                  style="
                    font-size: 20px;
                    font-style: italic;
                    margin-left: 105px;
                    margin-top: 0;
                  "
                >
                  <li>"search result 1"</li>
                  <li>"search result 2"</li>
                  <li>"..."</li>
                </ul>
              </div>
              <h4 style="font-size: 25px; color: black">Response</h4>
            </div>
          </section>

          <section>
            <h3>Benefits of Base RAG</h3>
            <ul>
              <li>
                Search is much more flexible and relaxed than traditional
                approaches.
              </li>
              <li>Great at answering specific/narrow questions.</li>
              <li>
                The sources used to answer a question are directly accessible.
              </li>
              <li>Straighforward and not complicated to maintain.</li>
            </ul>
          </section>

          <section>
            <h3>Limitations</h3>
            <ul>
              <li>
                Not so great at answering questions that require a
                <b>combination</b> of different sources.
              </li>
              <li>Misses a <b>global</b> view on the data.</li>
              <li>Might miss <b>exact</b> matches.</li>
            </ul>
          </section>
        </section>

        <!-- Lab session 2 -->
        <section>
          <section>
            <h2>RAG Hands on</h2>
          </section>

          <section>
            <img
              src="https://api.qrserver.com/v1/create-qr-code/?data=https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/02_rag_querying.ipynb&size=250x250"
              alt="https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/02_rag_querying.ipynb"
            /><br />
            <a
              href="https://colab.research.google.com/github/qaecy/built2025/blob/main/notebooks/02_rag_querying.ipynb"
              >Notebook 2</a
            >
          </section>
        </section>

        <!-- Perspective -->
        <section>
          <section>
            <h2>Perspective</h2>
          </section>

          <section>
            <p>The richer the input the richer the output</p>
          </section>

          <section
            data-background-iframe="dist/html/cytoscape/document-entities-5.html"
          >
            <img
              src="dist/img/fallback/Decentral-G13.png"
              alt=""
              class="print-fallback"
            />
          </section>

          <section
            data-background-image="dist/img/misc/ne_link.svg"
            data-background-size="80vh"
          ></section>

          <section>
            <ul>
              <li>Same entity represented in multiple contexts</li>
              <li>Different visual representaitions of the same entity</li>
              <li>Different historical versions of the same entity</li>
            </ul>
          </section>

          <section>
            <img src="dist/img/misc/saas-is-dead.jpeg" alt="SaaS is dead?" />
          </section>

          <section>
            <img src="dist/img/rag/Agentic-RAG1.png" height="500px"><br>
            <a
              href="https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/"
              >How I finally got agentic RAG to work right</a
            >
            <aside class="notes">
              Agentic setups or Agent as a Service is probably the new way for us to interact with our data.
              In this context it's also relevant to mention MCP: Model Context Protocol. Provides clear instructions on how the LLM communicates with a service to for example create a database entry.
            </aside>
          </section>

          <section
            data-background-image="dist/img/cue/cue.png"
            data-background-size="100vh"
          ></section>

        </section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script src="js/print-fallback.js"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,
        pdfSeparateFragments: false,
        scrollActivationWidth: null, // No mobile scroll
        // showNotes: true,
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
      });
    </script>
  </body>
</html>
